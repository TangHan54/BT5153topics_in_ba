{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Assignment: McDonald's Sentiment Data Analysis - Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "McDonald’s receives thousands of consumer comment on their website every day and many of them are negative. Their corporate employees do not have the time to browse through every single comment, but they do want to read a subset that they are most interested in. In particular, articles about the rude service of their employees have recently surfaced on social media. In order to take appropriate action, they would now like to review comments about **rude service**. \n",
    "\n",
    "You are hired to develop a system that ranks each comment by the **likelihood that it is referring to rude service**. They will use this system to build a “rudeness dashboard” for their corporate employees, so that the employees can spend a few minutes each day examining the **most relevant recent comments**.\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "McDonald’s used the CrowdFlower platform to pay humans to hand-annotate approximately 1500 comments with the type of complaint. The list of complaint types can be found below, with the encoding used listed in parentheses: \n",
    "- Bad Food (BadFood)\n",
    "- Bad Neighborhood (ScaryMcDs)\n",
    "- Cost (Cost)\n",
    "- Dirty Location (Filthy)\n",
    "- Missing Item (MissingFood)\n",
    "- Problem with Order (OrderProblem)\n",
    "- Rude Service (RudeService)\n",
    "- Slow Service (SlowService)\n",
    "- None of the above (na) \n",
    "\n",
    "You will be asked to perform some tasks. In the midst of these tasks, some MCQs will be asked. You are to select the best possible option as your answer. Please answer them accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Python 2: use print only as a function\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Read **'mcdonalds.csv'** into a pandas DataFrame and examine it. (Instructions: mcdonalds.csv can be found in “IVLE Workbin > Midterm Assignment > data”) \n",
    "\n",
    "A description of the more important columns to get you started: \n",
    "- The **policies_violated** column lists the type of complaint. If there is more than one type, the types are separated by newline characters.\n",
    "- The **policies_violated:confidence** column lists CrowdFlower's confidence in the judgments of its human annotators for that row (higher is better).\n",
    "- The **city** column is the McDonald's location.\n",
    "- The **review** column is the actual text comment.\n",
    "\n",
    "**Please answer Question 1 as in midterm.pdf.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Went here after work for a quick Mickey D fix. I had order a 6 piece chicken nuggets meal. Sorry to say but I think it will be my last time here. Don't get me wrong, the food tasted fine by my insides didn't think so.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/mcdonalds.csv')\n",
    "df.loc[302,'review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Remove any rows from the DataFrame in which the policies_violated column has a null value.\n",
    "- **Note**: Null values are also known as “missing values”, and are encoded in pandas with the special value “NaN’. This is different from the “na” encoding used by CrowdFlower to denote “None of the above”. Rows that contain “na” should not be removed.\n",
    "\n",
    "- **Note**: pandas.notnull() can return true if the object is not null and false if the object is null.\n",
    "\n",
    "**Please answer Question 2 as in midterm.pdf.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "0\n",
      "(1471, 11)\n"
     ]
    }
   ],
   "source": [
    "print(sum(df.policies_violated.isna()))\n",
    "df = df[df.policies_violated.notnull()]\n",
    "print(sum(df.policies_violated.isna()))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Add a new column to the DataFrame called **\"rude\"** that is 1 if the **policies_violated** column contains the text \"RudeService\", and 0 if the **policies_violated** column does not contain \"RudeService\". The \"rude\" column is going to be your response variable, so check how many zeros and ones it contains.\n",
    "\n",
    "- **Note**: .iloc[] function can be used to select dataframe rows by position\n",
    "\n",
    "**Please answer Question 3 as in midterm.pdf.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.654\n"
     ]
    }
   ],
   "source": [
    "df['rude'] = [1 if 'RudeService' in review else 0 for review in df.policies_violated]\n",
    "print(1 - sum(df.head(500).rude)/500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Define X using the **review** column and y using the **rude** column. Split X and y into training and testing sets (using the parameter **`random_state=1`**). Use CountVectorizer (with the **default parameters**) to create document-term matrices from X_train and X_test. \n",
    "- Note: Please remember to follow the instructions carefully by setting the parameters as required for reproducibility of results. \n",
    "\n",
    "**Please answer Question 4 as in midterm.pdf.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7300\n",
      "7300\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X = df.review\n",
    "y = df.rude\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,random_state=1)\n",
    "vectorizer = CountVectorizer()\n",
    "dt_train = vectorizer.fit_transform(x_train)\n",
    "dt_test = vectorizer.transform(x_test)\n",
    "print(dt_train.shape[1])\n",
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Fit a Multinomial Naive Bayes model to the training set, calculate the **predicted probabilities** for the testing set, and then calculate the AUC. Repeat this task using a logistic regression model to compare which of the two models achieves a better AUC. \n",
    "- **Note**: McDonald’s requires you to rank the comments by the likelihood that they refer to rude service. In this case, classification accuracy is NOT the relevant evaluation metric. Area Under Curve (AUC) is a more useful evaluation metric for this scenario, since it measures the ability of the classifier to assign higher predicted probabilities to positive instances than to negative instances. \n",
    "\n",
    "**Please answer Questions 5 and 6 as in midterm.pdf.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26854852118209765\n",
      "0\n",
      "0.8426005404546177\n",
      "0\n",
      "0.8233985058019394\n",
      "0.019202034652678335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(dt_train, y_train)\n",
    "y_pred_prob =[res[1] for res in nb.predict_proba(dt_test)]\n",
    "y_pred_class = nb.predict(dt_test)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob, pos_label=1)\n",
    "auc_nb = metrics.auc(fpr, tpr)\n",
    "print(y_pred_prob[4])\n",
    "print(y_pred_class[4])\n",
    "print(auc_nb)\n",
    "\n",
    "lg = LogisticRegression()\n",
    "lg.fit(dt_train, y_train)\n",
    "y_pred_prob = [res[1] for res in lg.predict_proba(dt_test)]\n",
    "y_pred_class = lg.predict(dt_test)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob, pos_label=1)\n",
    "auc_lg = metrics.auc(fpr, tpr)\n",
    "print(y_pred_class[4])\n",
    "print(auc_lg)\n",
    "print(auc_nb - auc_lg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Using Naive Bayes, try **tuning CountVectorizer** using some of the techniques we learned in class. Check the testing set AUC after each change, and find the set of parameters that increases AUC the most. (This is meant for your own learning experience)\n",
    "- **Hint**: It is highly recommended that you adapt the **`tokenize_test()`** function from class for this purpose, since it will allow you to iterate quickly through different sets of parameters. \n",
    "\n",
    "\n",
    "**Please answer Questions 7 and 8 as in midterm.pdf.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1732\n",
      "0.9104643300897306\n",
      "1\n",
      "0.8621522810364012\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_df = 0.3, min_df = 4)\n",
    "dt_train = vectorizer.fit_transform(x_train)\n",
    "dt_test = vectorizer.transform(x_test)\n",
    "print(dt_train.shape[1])\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(dt_train, y_train)\n",
    "y_pred_prob =[res[1] for res in nb.predict_proba(dt_test)]\n",
    "y_pred_class = nb.predict(dt_test)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob, pos_label=1)\n",
    "auc_nb = metrics.auc(fpr, tpr)\n",
    "print(y_pred_prob[4])\n",
    "print(y_pred_class[4])\n",
    "print(auc_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
